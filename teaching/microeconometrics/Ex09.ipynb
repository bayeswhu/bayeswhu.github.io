{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Consider the medical expenditures data example of the class, except use `totexp` rather than `ltotexp` as the dependent variable. Use the same sample, so still drop if ltotexp==. Estimate the parameters of the model with q = 0.5, and comment on the parameter estimates. Reestimate at the quantiles 0.25, 0.50, and 0. 75. Compare these estimates with each other (and their precision) and also with OLS\n",
    "(with robust standard errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Use the medical expenditures data of the class. Show that the median of `totexp` equals the exponential of the median of `ltotexp`. Now add a single regressor, the indicator `female`. Then any conditional quantile function must be linear in the regressor, with $Q_q(\\ln y|x) = \\alpha_{q1} + \\alpha_{q2}female$ and $Q_q(y|x) = \\beta_{q1} + \\beta_{q2}female$. Show that if we estimate `1totexp ~ female`, then predict, and finally exponentiate the prediction, we get the same prediction as that directly from `totexp ~ female`. Now add another regressor, say, `totchr`. Then the conditional quantile may no longer be linear in `female` and `totchr`. Repeat the prediction exercise and show that the invariance under the transformation property no longer holds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Use the medical expenditures data example of the class with the dependent variable `1totexp`. Test the hypothesis that heteroskedasticity is a function of the single variable `totchr`, which measures the number of chronic conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Consider the heteroskeda.stic regression example of the class. Change the specification of the variance function so that the variance function is a function of $x_3$ and not $x_2$; i.e., reverse the roles of $x_2$ and $x_3$. Estimate QRs for the generated data for q = 0.25, 0.50, and 0.75. Compare the results you obtain in class. Next vary the coefficient of $x_3$ in the variance function, and study its impact on the QR estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Consider the heteroskedasticity example of the class. There the regression error is symmetrically distributed. Suppose we want to study whether the differences between OLS and QR results are sensitive to the shape of the error distribution. Make suitable changes to the simulation data, and implement an analysis similar to that in class with asymmetric errors. For example, first draw `u` from the uniform distribution and then apply the transformation $-\\lambda\\log(u)$, where $\\lambda > 0$. (This generates draws from the exponential distribution with a mean of $\\lambda$ and a variance of $\\lambda^2$.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "livereveal": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
