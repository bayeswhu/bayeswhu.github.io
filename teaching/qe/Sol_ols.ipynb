{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "hide-output": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:               logpgp95   R-squared:                       0.689\n",
            "Model:                            OLS   Adj. R-squared:                  0.679\n",
            "Method:                 Least Squares   F-statistic:                     74.05\n",
            "Date:                Wed, 13 Mar 2019   Prob (F-statistic):           1.07e-17\n",
            "Time:                        04:59:05   Log-Likelihood:                -62.031\n",
            "No. Observations:                  70   AIC:                             130.1\n",
            "Df Residuals:                      67   BIC:                             136.8\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          2.4782      0.547      4.530      0.000       1.386       3.570\n",
            "avexpr         0.8564      0.082     10.406      0.000       0.692       1.021\n",
            "resid         -0.4951      0.099     -5.017      0.000      -0.692      -0.298\n",
            "==============================================================================\n",
            "Omnibus:                       17.597   Durbin-Watson:                   2.086\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.194\n",
            "Skew:                          -1.054   Prob(JB):                     9.19e-06\n",
            "Kurtosis:                       4.873   Cond. No.                         53.8\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "# Load in data\n",
        "df4 = pd.read_stata('https://github.com/QuantEcon/QuantEcon.lectures.code/raw/master/ols/maketable4.dta')\n",
        "\n",
        "# Add a constant term\n",
        "df4['const'] = 1\n",
        "\n",
        "# Estimate the first stage regression\n",
        "reg1 = sm.OLS(endog=df4['avexpr'],\n",
        "              exog=df4[['const', 'logem4']],\n",
        "              missing='drop').fit()\n",
        "\n",
        "# Retrieve the residuals\n",
        "df4['resid'] = reg1.resid\n",
        "\n",
        "# Estimate the second stage residuals\n",
        "reg2 = sm.OLS(endog=df4['logpgp95'],\n",
        "              exog=df4[['const', 'avexpr', 'resid']],\n",
        "              missing='drop').fit()\n",
        "\n",
        "print(reg2.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output shows that the coefficient on the residuals is statistically\n",
        "significant, indicating $ avexpr_i $ is endogenous"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "hide-output": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "β_0 = 4.6\n",
            "β_1 = 0.53\n"
          ]
        }
      ],
      "source": [
        "# Load in data\n",
        "df1 = pd.read_stata('https://github.com/QuantEcon/QuantEcon.lectures.code/raw/master/ols/maketable1.dta')\n",
        "df1 = df1.dropna(subset=['logpgp95', 'avexpr'])\n",
        "\n",
        "# Add a constant term\n",
        "df1['const'] = 1\n",
        "\n",
        "# Define the X and y variables\n",
        "y = np.asarray(df1['logpgp95'])\n",
        "X = np.asarray(df1[['const', 'avexpr']])\n",
        "\n",
        "# Compute β_hat\n",
        "β_hat = np.linalg.solve(X.T @ X, X.T @ y)\n",
        "\n",
        "# Print out the results from the 2 x 1 vector β_hat\n",
        "print(f'β_0 = {β_hat[0]:.2}')\n",
        "print(f'β_1 = {β_hat[1]:.2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is also possible to use `np.linalg.inv(X.T @ X) @ X.T @ y` to solve\n",
        "for $ \\beta $, however `.solve()` is preferred as it involves fewer\n",
        "computations"
      ]
    }
  ],
  "metadata": {
    "filename": "ols.rst",
    "kernelspec": {
      "display_name": "Python",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "title": "Linear Regression in Python"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}